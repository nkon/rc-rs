Design Note of `rc`
===================

* 入力としては、Readerからの文字列を受け取る。それをlexerでトークン列に分解し`Vec<Token>`とする。Parserは`Vec<Token>`を受け取り、インデックスを移動させることで（イテレータを使わずに）パーズして、ASTを返す。Parserは`Vec<Token>`とパースする箇所のインデックスを受け取り、ASTと読み進めた後のインデックスをタプルとして返す。インデックスをポインターとして受け取ってそれを変更するようにはなっていない。それぞれの文法要素に対応するパーザ関数があり、再帰下降でパースしてゆく。ASTをevalすることで計算結果を得る。

Tokenはenumとして実装し、それぞれの枝に値を持っている。

Lexerの特徴として、`-100`を、単項演算子`-`と整数リテラル（`100`）へ分解するようにしている。単項演算子として`-`を消費してしまうほうが簡単な実装になるからだ。デメリットとしては、たとえば`u8`で−128を表すことができなくなる。


```rust
#[derive(Debug, Copy, Clone, PartialEq)]
pub enum Token {
    Num(u64),
    Op(char),
}
```

ASTはstrutとして実装し、`NodeType`がノードの種類を表し、他のメンバーには、それぞれの要素に必要な値が入っている。

```rust
#[derive(Clone, PartialEq)]
pub enum NodeType {
    None,
    Num,   // value <- value
    Unary, // op <- operator, child。[0] <- operand
    BinOp, // op <- operator, child[0] <- lhs, child[1] <- rhs
}

pub struct Node {
    pub ty: NodeType,
    pub value: u64,
    pub op: Token,
    pub child: Vec<Node>, // child[0]: LHS, child[1]: RHS
}
```

## オブジェクト指向

今回は、インタプリタ全体の動作を決定する情報を `struct Env`にまとめ、`&mut env`として必要な関数には引数として渡すようにした。これを、`&mut self`として渡すとオブジェクト指向になる。やってることは同じだが、見た目と書く手間のバランスだ。

## ファイル分割

`main.rs`にはオプション処理など必要最低限のことだけ行って、あとは、`lib.rs`および、そこから呼び出されるライブラリに制御を移す。Lib crateではユニットテストが使えるので、それを最大限有効活用するため。

## エラー処理

パーサにエラーはつきもの。まずは、`Result<T, String>`として文字列形式で、人間可読なエラーメッセージを返すようにする。

## テスト

電卓も言語処理系だ。入力があって出力がある。定めた仕様どおりにコードを書くと、とりあえずは動く。しかし、言語処理系は構文要素の組み合わせが無限にある。ちょっと動くようになったら自分でドッグフードを食べてみるが、いろいろなケースでバグに出会う。そういうのはすぐにテストケースにまとめて、それが正常実行できるようにデバッグを行う。テストケースが溜まっていき、ワンコマンドで回帰テストを実行する。テストがあるからこそ、チャレンジングなリファクタリングも実行できる。後半になればなるほど、開発スピードが上がる。

今では当たり前のスタイルだが、勤務先…。

## インクリメンタルな開発

これも毎回書いているが、インクリメンタルな開発が推奨される。

たとえば、電卓に定数"pi"の機能を実装するとき。「将来的にユーザ定義変数も追加したいな」とか思い描いて、最初から辞書検索機能を実装するのは「悪手」である。まず"pi"だけが確実に機能する実装を作り、テストを行う。そこから、ユーザ定義変数などの追加機能を実装するのだ。

当然、高機能な電卓ではユーザ定義の変数、関数の機能が求められる。場合によってはスコープなどで入れ子になったネームスペースなども必要になるだろう。そこで要求仕様書にそう書くとしよう。すると、入れ子になったネームスペースを参照した、変数・関数辞書ができるまで、最初のテストが実行されない。それまでに要する開発工数、テスト作成工数は増大する。一方、実装最初のパーサのテストは、固定の"pi"が解釈できさえすば実行できる。

また、仕様書には想定される実装に基づいたデータ構造やモジュール構造に依存した記述がなされる。それらは、実装・テストによる確認を経ていないため、最適解ではなかったり、設計書の記述時点で間違っていたりする。ソフトウエアは複雑なので、実装・テストによる確認を経ずに、頭の中だけで仕様を書き下して、それがバグ無く一発で動くことは極めて困難だ。

これが「仕様定義」→「実装」のウォーターフォール開発がソフトウエアに不適合である、主要な理由のひとつつだ。

## 開発環境

rustのコンパイラは厳しいが親切。コンパイル時にエラーが出まくるのは有名な話だが、どう直せばよいかも提示してくれる。初心者が遭遇するエラーは典型的なので、コンパイラがヒントとして提示するように直していけば、たいてい解消される。VS Codeを使っていると、コンパイラを通さずとも赤線が引かれるので、注釈通りに修正していけばよい。コンパイラエラーだけでなく、clippyも適切な改善をアドバイスしてくれる。ひととおり修正が完了したら、コミットする前に`cargo fmt`と`cargo clippy`を実行する習慣をつけるとよいだろう。

グローバル変数が事実上使えない、ボローチェッカーが厳しいなどもある。これも、コンパイラの言う通りに修正することで、メモリーリークやデータ競合リスクがないコードを書くギブスみたいなものだ。慣れればそれらに引っかからないコードが書けるようになる。そのためには、自然とデータの寿命と所有者・だれが変更するか、に気を使わなければならない。それらは、当然Cなどでも、きちんと考えられているべき事項なのだ。

コンパイラがザルだと、全部自分でチェックしなければならない。ストレス。

今時の環境なので、テストやドキュメンテーションも言語設計レベルで統合されており、どのフレームワークを使うかなどの迷いがない。フォーマットも宗派がない。そのような自転車置き場の議論がないこともRust開発環境の快適さだと思う。

VS Codeの環境がGitと密に結合していることも、テスト＆修正＆コミットのサイクルを細かく回すことに一役買っている。従来の「保存」の代わりがコミットのようなものだ。そうなることで、自動セーブ機能がさらに合理的なものとなる。保存しないと、ビルドにも反映しないし、何かの拍子に編集が失われるとは、明らかに不便だ。保存したとしても、それはテストが通っていないのであれば、本当に保存する価値があるのだろうか。テストが通れば、その変更単位についてコミット・コメントが付く。理由・履歴・差分を参照しながら、いつでもその場所に戻れるのが「セーブ」ポイントというものだろう。ただし、これは個人開発の場合。グループ開発の場合にはPushする前に、ffしてコミットを（他の人にもわかる程度には）きれいにしましょう。


