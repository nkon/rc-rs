Design Note of `rc`
===================

## Lexer

1行入力として`String`を受け取り、それをトークン列に分解し`Result<Vec<Token>, String>`を返す。


`Token`は`enum`として実装する。それぞれの枝に値を持っている。


```rust
#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    Num(i128),
    FNum(f64),
    Op(TokenOp),
    Ident(String),
}
```

Lexerの特徴として、`-100`を、単項演算子`-`と整数リテラル（`100`）へ分解するようにしている。単項演算子として`-`を消費してしまうほうが簡単な実装になるからだ。デメリットとしては、たとえば`u8`で−128を表すことができなくなる。

実装としては、いったん入力を`Vec<char>`に変換してインデックスでアクセスする。Iteratorを使わない。この方が型修飾を減らしてCっぽく実装できる。インデックスは`&mut`で受け取らず、コピー渡しの引数で受取、タプルで更新値を返す。この方が「借用」に煩わされない。

## Parser

パーサと評価系は再帰がすべて。手書きの再帰降順パーサを用いてトークン列をASTに変換し、ASTを再帰的に辿って値を決定する。文法と評価ツリーのトラバースがしっかりと設計できていれば、自分の予想外のことまでうまくいく。単純な再帰ではなく、複数の関数の間を循環するような再帰になっているので、どこに再帰させるかを間違えないようにだけ注意が必要。

Parserは`Vec<Token>`を受け取り、`Result<Node, String>`を返す。`Node`は`child: Vec<Node>`を持ち、ASTを構成する。Lexerとおなじく、入力はIteratorではなく配列とインデックスでアクセスする。`Node`は`enum`ではなく構造体になっている。`NodeType`がノードの種類を表し、他のメンバーには、それぞれの要素に必要な値が入っている。`enum`の方がrustっぽいのだが、エラー処理が面倒だったので構造体になっている。将来的には`enum`にしたい。

```rust
pub struct Node {
    pub ty: NodeType,
    pub value: i128,
    pub fvalue: f64,
    pub op: Token,
    pub child: Vec<Node>, // child[0]: LHS, child[1]: RHS
}
```

## Eval

Parserが返したASTをevalすることで計算結果を得る。

## オブジェクト指向

今回は、インタプリタ全体の動作を決定する情報を `struct Env`にまとめ、`&mut env`として必要な関数には引数として渡すようにした。これを、`&mut self`として渡すとオブジェクト指向になる。やってることは同じだが、見た目と書く手間のバランスだ。

## ファイル分割

`main.rs`にはオプション処理など必要最低限のことだけ行って、あとは、`lib.rs`および、そこから呼び出されるライブラリに制御を移す。Lib crateではユニットテストが使えるので、それを最大限有効活用するため。

## エラー処理

パーサにエラーはつきもの。まずは、`Result<T, String>`として文字列形式で、人間可読なエラーメッセージを返すようにする。

## 端末制御

別のプロジェクトでは `termion`を使っていたが、`rc`では、Windowsとのクロスプラットフォーム性を重視して`crossterm`を用いるようにした。依存するクレートは増えるがLinuxでもWindowsでも動作するし、こちらのほうがより多機能だ。書き方は異なるが使い方は似ている。当然であるが、内部のデータ構造の編集操作と、表示部分やイベントハンドリングを分けておくのがコツ。移植性のためだけでなく、編集操作を分けておくとユニットテストもやりやすい。

## テスト

電卓も言語処理系だ。入力があって出力がある。定めた仕様どおりにコードを書くと、とりあえずは動く。しかし、言語処理系は構文要素の組み合わせが無限にある。ちょっと動くようになったら自分でドッグフードを食べてみるが、いろいろなケースでバグに出会う。そういうのはすぐにテストケースにまとめて、それが正常実行できるようにデバッグを行う。テストケースが溜まっていき、ワンコマンドで回帰テストを実行する。テストがあるからこそ、チャレンジングなリファクタリングも実行できる。後半になればなるほど、開発スピードが上がる。

今では当たり前のスタイルだが、勤務先…。

## インクリメンタルな開発

これも毎回書いているが、インクリメンタルな開発が推奨される。

たとえば、電卓に定数"pi"の機能を実装するとき。「将来的にユーザ定義変数も追加したいな」とか思い描いて、最初から辞書検索機能を実装するのは「悪手」である。まず"pi"だけが確実に機能する実装を作り、テストを行う。そこから、ユーザ定義変数などの追加機能を実装するのだ。

当然、高機能な電卓ではユーザ定義の変数、関数の機能が求められる。場合によってはスコープなどで入れ子になったネームスペースなども必要になるだろう。そこで要求仕様書にそう書くとしよう。すると、入れ子になったネームスペースを参照した、変数・関数辞書ができるまで、最初の変数・関数のテストが実行されない。それまでに要する開発工数、テスト作成工数は増大する。一方、実装最初のパーサのテストは、固定の"pi"が解釈できさえすば実行できる。最初の間に合わせの実装から、最終的な実装への書き換えの手間が発生するが、インクリメンタルに開発することでスコープを小さく保つことのメリットは十分に見合う。

また、仕様書には想定される実装に基づいたデータ構造やモジュール構造に依存した記述がなされる。それらは、実装・テストによる確認を経ていないため、最適解ではなかったり、設計書の記述時点で間違っていたりする。ソフトウエアは複雑なので、実装・テストによる確認を経ずに、頭の中だけで仕様を書き下して、それがバグ無く一発で動くことは極めて困難だ。

これが「仕様定義」→「実装」のウォーターフォール開発がソフトウエアに不適合である、主要な理由のひとつつだ。

経験のある開発者は、たとえ壮大な仕様書を渡されたとしてもその意を汲み取りながら、ステップバイステップに分解して、最終的には要求を満たすが仕様書よりベターな実装を仕上げるだろう。しかし、中級の開発者にそれを期待するのは難しい。

## 開発環境

rustのコンパイラは厳しいが親切。コンパイル時にエラーが出まくるのは有名な話だが、どう直せばよいかも提示してくれる。初心者が遭遇するエラーは典型的なので、コンパイラが提示するヒントにしたがって修正していけば、たいてい解消される。VS Codeを使っていると、コンパイラを通さずとも赤線が引かれるので、注釈通りに修正していけばよい。コンパイラエラーだけでなく、clippyも適切な改善をアドバイスしてくれる。ひととおり修正が完了したら、コミットする前に`cargo fmt`と`cargo clippy`を実行する習慣をつけるとよいだろう。

グローバル変数が事実上使えない、ボローチェッカーが厳しいなどもある。これも、コンパイラの言う通りに修正することで、メモリーリークやデータ競合リスクがないコードを書くギブスみたいなものだ。慣れればそれらに引っかからないコードが書けるようになる。そのためには、自然とデータの寿命と所有者・だれが変更するか、に気を使わなければならない。それらは、当然Cなどでも、きちんと考えられているべき事項なのだ。

コンパイラがザルだと、全部自分でチェックしなければならない。ストレス。

今時の環境なので、テストやドキュメンテーションも言語設計レベルで統合されており、どのツールを使うかなどの迷いがない。フォーマットも宗派がない。そのような自転車置き場の議論がないこともRust開発環境の快適さだと思う。C言語の`{`,`}`のインデントの議論で丸一日潰れたことを思い出す。

VS Codeの環境がGitと密に結合していることも、テスト＆修正＆コミットのサイクルを細かく回すことに役立っている。従来の「保存」の代わりがコミットのようなものだ。そうなることで、自動セーブ機能がさらに合理的なものとなる。保存しないと、ビルドにも反映しないし、何かの拍子に編集が失われることは明らかに不便だ。保存したとしても、それはテストが通っていないのであれば、本当に「保存」する価値があるのだろうか。テストが通れば、その変更単位についてコミット・コメントが付く。理由・履歴・差分を参照しながら、いつでもその場所に戻れるのが「セーブ」ポイントというものだろう。ただし、これは個人開発の場合。グループ開発の場合にはPushする前にコミットを（他の人にもわかる程度には）きれいにしましょう。

Windows版の開発とVS-Code remoteを使ったWSL2上の開発が、ほぼ同じ環境で実施できるのも素晴らしい。

## シングルバイナリ

* static link
* musl

